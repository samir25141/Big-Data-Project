{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed066c62-54c7-4e69-8959-c0a05eb8575f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df=spark.read.csv(\"/FileStore/tables/ADSI_Table_1A_12.csv\")\n",
    "#df.show()\n",
    "#display(df)\n",
    "\n",
    "from pyspark.sql.types import StructType,StringType,IntegerType,StructField\n",
    "\n",
    "accident_schema=StructType([StructField('Sl.no.',IntegerType(),True),StructField('State',StringType(),True),StructField('Collisions - Cases', IntegerType(), True), StructField('Collisions - Injured', IntegerType(), True), StructField('Collision - Died', IntegerType(), True), StructField('Derailments -Cases', IntegerType(), True), StructField('Derailment - Injured', IntegerType(), True), StructField('Derailment - Died', IntegerType(), True), StructField('Fall from Train/Collision with People at Tracks - Cases', IntegerType(), True), StructField('Fall from Train/Collision with People at Tracks - Injured', IntegerType(), True), StructField('Fall from Train/Collision with People at Tracks - Died', IntegerType(), True), StructField('Explosion/Fire - Cases', IntegerType(), True), StructField('Explosion/Fire - Injured', IntegerType(), True), StructField('Explosion/Fire - Died', IntegerType(), True), StructField('Others - Cases', IntegerType(), True), StructField('Others - Injured', IntegerType(), True), StructField('Others - Died', IntegerType(), True), StructField('Total - Cases', IntegerType(), True), StructField('Total - Injured', IntegerType(), True), StructField('Total - Died', IntegerType(), True)])\n",
    "\n",
    "df=spark.read.csv(\"/FileStore/tables/ADSI_Table_1A_12.csv\")\n",
    "df=spark.read.schema(accident_schema).csv(\"/FileStore/tables/ADSI_Table_1A_12.csv\")\n",
    "display(df)\n",
    "\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "\n",
    "spark.sql(\"SELECT State,count(State)FROM accident_datasets GROUP BY State\").show()\n",
    "\n",
    "#df=df.withColumnRenamed(\"Total - Total\",\"Total_Affected\")\n",
    "#df.createOrReplaceTempView(\"disaster_data\")\n",
    "\n",
    "df=df.withColumnRenamed(\"Total - Cases\", \"Total_accident_cause\")\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "\n",
    "Total_accident_cause = spark.sql(\"\"\" \n",
    " SELECT State, SUM(Total_accident_cause) as Total_accident_cause\n",
    " FROM accident_datasets \n",
    " GROUP BY State \n",
    "\"\"\") \n",
    "Total_accident_cause.show() \n",
    "\n",
    "df=df.withColumnRenamed(\"Total - Injured\", \"Total_accident_injured\")\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "\n",
    "Total_accident_injured = spark.sql(\"\"\" \n",
    " SELECT State, SUM(Total_accident_injured) as Total_accident_injured\n",
    " FROM accident_datasets \n",
    " GROUP BY State \n",
    "\"\"\") \n",
    "Total_accident_injured.show() \n",
    "\n",
    "\n",
    "df=df.withColumnRenamed(\"Total - Died\", \"Total_accident_died\")\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "\n",
    "Total_accident_died = spark.sql(\"\"\" \n",
    " SELECT State, SUM(Total_accident_died) as Total_accident_died\n",
    " FROM accident_datasets \n",
    " GROUP BY State \n",
    "\"\"\") \n",
    "Total_accident_died.show() \n",
    "\n",
    "\n",
    "#df=df.withColumnRenamed(\"Total - Cases\", \"Total_accident_cause\")\n",
    "#df=df.withColumnRenamed(\"Total - Injured\", \"Total_accident_injured\")\n",
    "df=df.withColumnRenamed(\"Total - Died\", \"Total_accident_died\")\n",
    "\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "\n",
    "Total_accident_died = spark.sql(\"\"\" \n",
    " SELECT State, AVG(Total_accident_died) as Total_accident_died\n",
    " FROM accident_datasets\n",
    " GROUP BY State \n",
    "\"\"\") \n",
    "Total_accident_died.show() \n",
    "\n",
    "df=df.withColumnRenamed(\"Total - Injured\", \"Total_accident_injured\")\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "Total_accident_injured = spark.sql(\"\"\" \n",
    " SELECT State, AVG(Total_accident_injured) as Total_accident_injured\n",
    " FROM accident_datasets\n",
    " GROUP BY State \n",
    "\"\"\") \n",
    "Total_accident_injured.show() \n",
    "\n",
    "df=df.withColumnRenamed(\"Total - Cause\", \"Total_accident_cause\")\n",
    "df.createOrReplaceTempView(\"accident_datasets\")\n",
    "Total_accident_cause = spark.sql(\"\"\" \n",
    " SELECT State, AVG(Total_accident_cause) as Total_accident_cause\n",
    " FROM accident_datasets\n",
    " GROUP BY State \n",
    "\"\"\") \n",
    "Total_accident_cause.show() \n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Total_accident_cause_pd= Total_accident_cause.toPandas()\n",
    "\n",
    "plt.bar(Total_accident_cause_pd['State'],Total_accident_cause_pd['Total_accident_cause'])\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total_accident_cause')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Total Number of People Affected in Each State')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Total_accident_injured_pd= Total_accident_injured.toPandas()\n",
    "\n",
    "plt.bar(Total_accident_injured_pd['State'],Total_accident_injured_pd['Total_accident_injured'])\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total_accident_injured')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Total Number of People injured in Each State')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "Total_accident_died_pd= Total_accident_died.toPandas()\n",
    "\n",
    "plt.bar(Total_accident_died_pd['State'],Total_accident_died_pd['Total_accident_died'])\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Total_accident_died')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Total Number of People died in Each State')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Big Data Project 2024-07-14 00:54:46",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
